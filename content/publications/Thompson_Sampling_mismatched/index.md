---
abstract: |-
  We consider Thompson Sampling (TS) for linear combinatorial semi-bandits and
  subgaussian rewards. We propose the first known TS whose finite-time regret
  does not scale exponentially with the dimension of the problem. We further
  show the “mismatched sampling paradox”: A learner who knows the rewards
  distributions and samples from the correct posterior distribution can perform
  exponentially worse than a learner who does not know the rewards and simply
  samples from a well-chosen Gaussian posterior.
slides: ""
publication_types:
  - Conference Paper
authors:
  - me
  - richardc
author_notes: []
math: true
publication: In *Neural Information Processing Systems 2024*
summary: |-
  We propose the first known Thompson Sampling for combinatorial bandits whose
  finite-time regret does not scale exponentially with the dimension of the
  problem. Suprisingly, considering any subgaussian distribution as a gaussian
  can produce exponentialy better result.
url_dataset: ""
url_project: ""
publication_short: In *NeurIPS2024* (Spotlight)
url_source: ""
url_video: ""
links:
  - type: pdf
    url: https://arxiv.org/abs/2410.05441
  - type: code
    url: https://github.com/RaymZhang/CTS-Mismatched-Paradox
title: "Thompson Sampling For Combinatorial Bandits: Polynomial Regret and
  Mismatched Sampling Paradox"
doi: ""
featured: false
tags: []
projects: []
image:
  caption: ""
  focal_point: ""
  preview_only: false
  filename: featured.jpg
date: 2024-12-09T00:00:00.000Z
url_slides: ""
publishDate: 2024-12-01T00:00:00.000Z
url_poster: ""
---
